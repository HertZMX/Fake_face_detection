{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPkohOLQOyXO2NBJcgBNUjb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#ShallowNet in the paper \"GAN is a Friend or Foe? A Framework to Detect Various Fake Face Images\""],"metadata":{"id":"pdzBCDQ1vCE0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RAsB8P9Fu_rm"},"outputs":[],"source":["# ShallowNet V1\n","def shallowNetv1(input_shape):\n","    model = Sequential()\n","    # Block 1\n","    model.add(Conv2D(96, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0001), name='C1',\n","                     input_shape=input_shape))\n","    model.add(BatchNormalization(name='B1'))\n","    model.add(Activation('relu', name='A1'))\n","    model.add(Dropout(0.25, name='O1'))\n","    model.add(Conv2D(96, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0001), name='C2'))\n","    model.add(BatchNormalization(name='B2'))\n","    model.add(Activation('relu', name='A2'))\n","    model.add(Dropout(0.25, name='O2'))\n","    model.add(Conv2D(96, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0001), name='C3'))\n","    model.add(BatchNormalization(name='B3'))\n","    model.add(Activation('relu', name='A3'))\n","    model.add(MaxPooling2D(pool_size=(3, 3), strides=2, name='P1'))\n","    model.add(Dropout(0.25, name='O3'))\n","    # Block 2\n","    model.add(Conv2D(192, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0001), name='C4'))\n","    model.add(BatchNormalization(name='B4'))\n","    model.add(Activation('relu', name='A4'))\n","    model.add(Dropout(0.25, name='O4'))\n","    model.add(Conv2D(192, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0001), name='C5'))\n","    model.add(BatchNormalization(name='B5'))\n","    model.add(Activation('relu', name='A5'))\n","    model.add(Dropout(0.25, name='O5'))\n","    model.add(Conv2D(192, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0001), name='C6'))\n","    model.add(BatchNormalization(name='B6'))\n","    model.add(Activation('relu', name='A6'))\n","    model.add(MaxPooling2D(pool_size=(3, 3), strides=2, name='P2'))\n","    model.add(Dropout(0.25, name='O6'))\n","    # Block 3\n","    model.add(Conv2D(257, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0001), name='C7'))\n","    model.add(BatchNormalization(name='B7'))\n","    model.add(Activation('relu', name='A7'))\n","    model.add(Dropout(0.25, name='O7'))\n","    model.add(Conv2D(257, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0001), name='C8'))\n","    model.add(BatchNormalization(name='B8'))\n","    model.add(Activation('relu', name='A8'))\n","    model.add(Dropout(0.25, name='O8'))\n","    model.add(Conv2D(257, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0001), name='C9'))\n","    model.add(BatchNormalization(name='B9'))\n","    model.add(Activation('relu', name='A9'))\n","    model.add(MaxPooling2D(pool_size=(3, 3), strides=2, name='P3'))\n","    model.add(Dropout(0.25, name='O9'))\n","    # Block 4\n","    model.add(Conv2D(311, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0001), name='C10'))\n","    model.add(BatchNormalization(name='B10'))\n","    model.add(Activation('relu', name='A10'))\n","    model.add(Dropout(0.25, name='O10'))\n","    model.add(Conv2D(311, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0001), name='C11'))\n","    model.add(BatchNormalization(name='B11'))\n","    model.add(Activation('relu', name='A11'))\n","    model.add(Dropout(0.25, name='O11'))\n","    model.add(Conv2D(311, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0001), name='C12'))\n","    model.add(BatchNormalization(name='B12'))\n","    model.add(Activation('relu', name='A12'))\n","    model.add(MaxPooling2D(pool_size=(3, 3), strides=2, name='P4'))\n","    model.add(Dropout(0.25, name='O12'))\n","    # Block 5\n","    model.add(Conv2D(396, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0001), name='C13'))\n","    model.add(BatchNormalization(name='B13'))\n","    model.add(Activation('relu', name='A13'))\n","    model.add(Dropout(0.25, name='O13'))\n","    model.add(Conv2D(396, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0001), name='C14'))\n","    model.add(BatchNormalization(name='B14'))\n","    model.add(Activation('relu', name='A14'))\n","    model.add(Dropout(0.25, name='O14'))\n","    model.add(Conv2D(396, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0001), name='C15'))\n","    model.add(BatchNormalization(name='B15'))\n","    model.add(Activation('relu', name='A15'))\n","    model.add(MaxPooling2D(pool_size=(3, 3), strides=2, name='P5'))\n","    model.add(Dropout(0.25, name='O15'))\n","    # Block 6\n","    model.add(Conv2D(437, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0001), name='C16'))\n","    model.add(BatchNormalization(name='B16'))\n","    model.add(Activation('relu', name='A16'))\n","    model.add(Dropout(0.25, name='O16'))\n","    model.add(Conv2D(437, (1, 1), padding='same', kernel_regularizer=regularizers.l2(0.0001), name='C17'))\n","    model.add(BatchNormalization(name='B17'))\n","    model.add(Activation('relu', name='A17'))\n","    model.add(Dropout(0.25, name='O17'))\n","    # Block 7\n","    model.add(Flatten(name='F1'))\n","    model.add(Dense(3933, kernel_regularizer=regularizers.l2(0.0001), name='D1'))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.25, name='O18'))\n","    model.add(Dense(2, activation='sigmoid'))\n","    model.name = 'shallowNetv1'\n","    return model\n","\n","# ShallowNet V2\n","def shallowNetv2(model_input):\n","    # Block1\n","    x = Conv2D(96, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.0001))(\n","        model_input)\n","    x = Dropout(0.25)(x)\n","    x = Conv2D(96, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.0001))(x)\n","    x = Dropout(0.25)(x)\n","    x = Conv2D(96, (3, 3), activation='relu', padding='same', strides=2, kernel_regularizer=regularizers.l2(0.0001))(x)\n","    x = Dropout(0.25)(x)\n","    # Block2\n","    x = Conv2D(192, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.0001))(x)\n","    x = Dropout(0.25)(x)\n","    x = Conv2D(192, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.0001))(x)\n","    x = Dropout(0.25)(x)\n","    x = Conv2D(192, (3, 3), activation='relu', padding='same', strides=2, kernel_regularizer=regularizers.l2(0.0001))(x)\n","    x = Dropout(0.25)(x)\n","    # Block3\n","    x = Conv2D(192, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.0001))(x)\n","    x = Dropout(0.25)(x)\n","    x = Conv2D(192, (1, 1), activation='relu', kernel_regularizer=regularizers.l2(0.0001))(x)\n","    x = Dropout(0.25)(x)\n","    # Block4\n","    x = Flatten()(x)\n","    x = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.25)(x)\n","    x = Dense(2, activation='sigmoid')(x)\n","    model = Model(model_input, x, name='shallowNetv2')\n","    return model\n","\t\n","# ShallowNet V3\n","def shallowNetv3(model_input):\n","    # block 1\n","    x = Conv2D(32, (5, 5), activation='relu', padding='valid', kernel_regularizer=regularizers.l2(0.0001))(model_input)\n","    x = Dropout(0.25)(x)\n","    x = Conv2D(32, (1, 1), activation='relu', kernel_regularizer=regularizers.l2(0.0001))(x)\n","    x = Dropout(0.25)(x)\n","    x = Conv2D(32, (1, 1), activation='relu', kernel_regularizer=regularizers.l2(0.0001))(x)\n","    x = MaxPooling2D((2, 2))(x)\n","    x = Dropout(0.25)(x)\n","    # block 2\n","    x = Conv2D(64, (3, 3), activation='relu', padding='valid', kernel_regularizer=regularizers.l2(0.0001))(x)\n","    x = Dropout(0.25)(x)\n","    x = Conv2D(64, (1, 1), activation='relu', kernel_regularizer=regularizers.l2(0.0001))(x)\n","    x = Dropout(0.25)(x)\n","    x = Conv2D(64, (1, 1), activation='relu', kernel_regularizer=regularizers.l2(0.0001))(x)\n","    x = MaxPooling2D((2, 2))(x)\n","    x = Dropout(0.25)(x)\n","    # block 3\n","    x = Conv2D(128, (3, 3), activation='relu', padding='valid', kernel_regularizer=regularizers.l2(0.0001))(x)\n","    x = Dropout(0.25)(x)\n","    x = Conv2D(32, (1, 1), activation='relu', kernel_regularizer=regularizers.l2(0.0001))(x)\n","    x = Dropout(0.25)(x)\n","    # block 4\n","    x = Flatten()(x)\n","    x = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.25)(x)\n","    x = Dense(2, activation='sigmoid')(x)\n","    model = Model(model_input, x, name='shallowNetv3')\n","    return model"]},{"cell_type":"markdown","source":["#ResNet models in the paper \"CNN-generated images are surprisingly easy to spot...for now\""],"metadata":{"id":"1uEYVYNq62Pk"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.utils.model_zoo as model_zoo\n","\n","\n","__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n","           'resnet152']\n","\n","\n","model_urls = {\n","    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n","    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n","    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n","    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n","    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n","}\n","\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=1, bias=False)\n","\n","\n","def conv1x1(in_planes, out_planes, stride=1):\n","    \"\"\"1x1 convolution\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = conv1x1(inplanes, planes)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes, stride)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = conv1x1(planes, planes * self.expansion)\n","        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n","        super(ResNet, self).__init__()\n","        self.inplanes = 64\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n","                               bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512 * block.expansion, num_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","        # Zero-initialize the last BN in each residual branch,\n","        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n","        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n","        if zero_init_residual:\n","            for m in self.modules():\n","                if isinstance(m, Bottleneck):\n","                    nn.init.constant_(m.bn3.weight, 0)\n","                elif isinstance(m, BasicBlock):\n","                    nn.init.constant_(m.bn2.weight, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                conv1x1(self.inplanes, planes * block.expansion, stride),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes * block.expansion\n","        for _ in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","\n","        return x\n","\n","\n","def resnet18(pretrained=False, **kwargs):\n","    \"\"\"Constructs a ResNet-18 model.\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","    \"\"\"\n","    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n","    if pretrained:\n","        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n","    return model\n","\n","\n","def resnet34(pretrained=False, **kwargs):\n","    \"\"\"Constructs a ResNet-34 model.\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","    \"\"\"\n","    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n","    if pretrained:\n","        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n","    return model\n","\n","\n","def resnet50(pretrained=False, **kwargs):\n","    \"\"\"Constructs a ResNet-50 model.\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","    \"\"\"\n","    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n","    if pretrained:\n","        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n","    return model\n","\n","\n","def resnet101(pretrained=False, **kwargs):\n","    \"\"\"Constructs a ResNet-101 model.\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","    \"\"\"\n","    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n","    if pretrained:\n","        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n","    return model\n","\n","\n","def resnet152(pretrained=False, **kwargs):\n","    \"\"\"Constructs a ResNet-152 model.\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","    \"\"\"\n","    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n","    if pretrained:\n","        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n","    return model"],"metadata":{"id":"zD_wyVFR62Yx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Xception model in the paper \"Xception: Deep Learning with Depthwise Separable Convolutions\" cited by the paper \"Detecting CNN-Generated Facial Images in Real-World Scenarios\" (as 7)\n","\n","more explanations: https://maelfabien.github.io/deeplearning/xception/#ii-in-keras\n"],"metadata":{"id":"5nO_efEc--Gi"}},{"cell_type":"code","source":["\"\"\"Xception V1 model for Keras.\n","\n","On ImageNet, this model gets to a top-1 validation accuracy of 0.790\n","and a top-5 validation accuracy of 0.945.\n","\n","Do note that the input image format for this model is different than for\n","the VGG16 and ResNet models (299x299 instead of 224x224),\n","and that the input preprocessing function\n","is also different (same as Inception V3).\n","\n","# Reference\n","\n","- [Xception: Deep Learning with Depthwise Separable Convolutions](\n","    https://arxiv.org/abs/1610.02357) (CVPR 2017)\n","\n","\"\"\"\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import os\n","import warnings\n","\n","from . import get_submodules_from_kwargs\n","from . import imagenet_utils\n","from .imagenet_utils import decode_predictions\n","from .imagenet_utils import _obtain_input_shape\n","\n","\n","TF_WEIGHTS_PATH = (\n","    'https://github.com/fchollet/deep-learning-models/'\n","    'releases/download/v0.4/'\n","    'xception_weights_tf_dim_ordering_tf_kernels.h5')\n","TF_WEIGHTS_PATH_NO_TOP = (\n","    'https://github.com/fchollet/deep-learning-models/'\n","    'releases/download/v0.4/'\n","    'xception_weights_tf_dim_ordering_tf_kernels_notop.h5')\n","\n","\n","def Xception(include_top=True,\n","             weights='imagenet',\n","             input_tensor=None,\n","             input_shape=None,\n","             pooling=None,\n","             classes=1000,\n","             **kwargs):\n","    \"\"\"Instantiates the Xception architecture.\n","\n","    Optionally loads weights pre-trained on ImageNet.\n","    Note that the data format convention used by the model is\n","    the one specified in your Keras config at `~/.keras/keras.json`.\n","\n","    Note that the default input image size for this model is 299x299.\n","\n","    # Arguments\n","        include_top: whether to include the fully-connected\n","            layer at the top of the network.\n","        weights: one of `None` (random initialization),\n","              'imagenet' (pre-training on ImageNet),\n","              or the path to the weights file to be loaded.\n","        input_tensor: optional Keras tensor\n","            (i.e. output of `layers.Input()`)\n","            to use as image input for the model.\n","        input_shape: optional shape tuple, only to be specified\n","            if `include_top` is False (otherwise the input shape\n","            has to be `(299, 299, 3)`.\n","            It should have exactly 3 inputs channels,\n","            and width and height should be no smaller than 71.\n","            E.g. `(150, 150, 3)` would be one valid value.\n","        pooling: Optional pooling mode for feature extraction\n","            when `include_top` is `False`.\n","            - `None` means that the output of the model will be\n","                the 4D tensor output of the\n","                last convolutional block.\n","            - `avg` means that global average pooling\n","                will be applied to the output of the\n","                last convolutional block, and thus\n","                the output of the model will be a 2D tensor.\n","            - `max` means that global max pooling will\n","                be applied.\n","        classes: optional number of classes to classify images\n","            into, only to be specified if `include_top` is True,\n","            and if no `weights` argument is specified.\n","\n","    # Returns\n","        A Keras model instance.\n","\n","    # Raises\n","        ValueError: in case of invalid argument for `weights`,\n","            or invalid input shape.\n","        RuntimeError: If attempting to run this model with a\n","            backend that does not support separable convolutions.\n","    \"\"\"\n","    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n","\n","    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n","        raise ValueError('The `weights` argument should be either '\n","                         '`None` (random initialization), `imagenet` '\n","                         '(pre-training on ImageNet), '\n","                         'or the path to the weights file to be loaded.')\n","\n","    if weights == 'imagenet' and include_top and classes != 1000:\n","        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n","                         ' as true, `classes` should be 1000')\n","\n","    # Determine proper input shape\n","    input_shape = _obtain_input_shape(input_shape,\n","                                      default_size=299,\n","                                      min_size=71,\n","                                      data_format=backend.image_data_format(),\n","                                      require_flatten=include_top,\n","                                      weights=weights)\n","\n","    if input_tensor is None:\n","        img_input = layers.Input(shape=input_shape)\n","    else:\n","        if not backend.is_keras_tensor(input_tensor):\n","            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n","        else:\n","            img_input = input_tensor\n","\n","    channel_axis = 1 if backend.image_data_format() == 'channels_first' else -1\n","\n","    x = layers.Conv2D(32, (3, 3),\n","                      strides=(2, 2),\n","                      use_bias=False,\n","                      name='block1_conv1')(img_input)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block1_conv1_bn')(x)\n","    x = layers.Activation('relu', name='block1_conv1_act')(x)\n","    x = layers.Conv2D(64, (3, 3), use_bias=False, name='block1_conv2')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block1_conv2_bn')(x)\n","    x = layers.Activation('relu', name='block1_conv2_act')(x)\n","\n","    residual = layers.Conv2D(128, (1, 1),\n","                             strides=(2, 2),\n","                             padding='same',\n","                             use_bias=False)(x)\n","    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n","\n","    x = layers.SeparableConv2D(128, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block2_sepconv1')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block2_sepconv1_bn')(x)\n","    x = layers.Activation('relu', name='block2_sepconv2_act')(x)\n","    x = layers.SeparableConv2D(128, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block2_sepconv2')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block2_sepconv2_bn')(x)\n","\n","    x = layers.MaxPooling2D((3, 3),\n","                            strides=(2, 2),\n","                            padding='same',\n","                            name='block2_pool')(x)\n","    x = layers.add([x, residual])\n","\n","    residual = layers.Conv2D(256, (1, 1), strides=(2, 2),\n","                             padding='same', use_bias=False)(x)\n","    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n","\n","    x = layers.Activation('relu', name='block3_sepconv1_act')(x)\n","    x = layers.SeparableConv2D(256, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block3_sepconv1')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block3_sepconv1_bn')(x)\n","    x = layers.Activation('relu', name='block3_sepconv2_act')(x)\n","    x = layers.SeparableConv2D(256, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block3_sepconv2')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block3_sepconv2_bn')(x)\n","\n","    x = layers.MaxPooling2D((3, 3), strides=(2, 2),\n","                            padding='same',\n","                            name='block3_pool')(x)\n","    x = layers.add([x, residual])\n","\n","    residual = layers.Conv2D(728, (1, 1),\n","                             strides=(2, 2),\n","                             padding='same',\n","                             use_bias=False)(x)\n","    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n","\n","    x = layers.Activation('relu', name='block4_sepconv1_act')(x)\n","    x = layers.SeparableConv2D(728, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block4_sepconv1')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block4_sepconv1_bn')(x)\n","    x = layers.Activation('relu', name='block4_sepconv2_act')(x)\n","    x = layers.SeparableConv2D(728, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block4_sepconv2')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block4_sepconv2_bn')(x)\n","\n","    x = layers.MaxPooling2D((3, 3), strides=(2, 2),\n","                            padding='same',\n","                            name='block4_pool')(x)\n","    x = layers.add([x, residual])\n","\n","    for i in range(8):\n","        residual = x\n","        prefix = 'block' + str(i + 5)\n","\n","        x = layers.Activation('relu', name=prefix + '_sepconv1_act')(x)\n","        x = layers.SeparableConv2D(728, (3, 3),\n","                                   padding='same',\n","                                   use_bias=False,\n","                                   name=prefix + '_sepconv1')(x)\n","        x = layers.BatchNormalization(axis=channel_axis,\n","                                      name=prefix + '_sepconv1_bn')(x)\n","        x = layers.Activation('relu', name=prefix + '_sepconv2_act')(x)\n","        x = layers.SeparableConv2D(728, (3, 3),\n","                                   padding='same',\n","                                   use_bias=False,\n","                                   name=prefix + '_sepconv2')(x)\n","        x = layers.BatchNormalization(axis=channel_axis,\n","                                      name=prefix + '_sepconv2_bn')(x)\n","        x = layers.Activation('relu', name=prefix + '_sepconv3_act')(x)\n","        x = layers.SeparableConv2D(728, (3, 3),\n","                                   padding='same',\n","                                   use_bias=False,\n","                                   name=prefix + '_sepconv3')(x)\n","        x = layers.BatchNormalization(axis=channel_axis,\n","                                      name=prefix + '_sepconv3_bn')(x)\n","\n","        x = layers.add([x, residual])\n","\n","    residual = layers.Conv2D(1024, (1, 1), strides=(2, 2),\n","                             padding='same', use_bias=False)(x)\n","    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n","\n","    x = layers.Activation('relu', name='block13_sepconv1_act')(x)\n","    x = layers.SeparableConv2D(728, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block13_sepconv1')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block13_sepconv1_bn')(x)\n","    x = layers.Activation('relu', name='block13_sepconv2_act')(x)\n","    x = layers.SeparableConv2D(1024, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block13_sepconv2')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block13_sepconv2_bn')(x)\n","\n","    x = layers.MaxPooling2D((3, 3),\n","                            strides=(2, 2),\n","                            padding='same',\n","                            name='block13_pool')(x)\n","    x = layers.add([x, residual])\n","\n","    x = layers.SeparableConv2D(1536, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block14_sepconv1')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block14_sepconv1_bn')(x)\n","    x = layers.Activation('relu', name='block14_sepconv1_act')(x)\n","\n","    x = layers.SeparableConv2D(2048, (3, 3),\n","                               padding='same',\n","                               use_bias=False,\n","                               name='block14_sepconv2')(x)\n","    x = layers.BatchNormalization(axis=channel_axis, name='block14_sepconv2_bn')(x)\n","    x = layers.Activation('relu', name='block14_sepconv2_act')(x)\n","\n","    if include_top:\n","        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n","        x = layers.Dense(classes, activation='softmax', name='predictions')(x)\n","    else:\n","        if pooling == 'avg':\n","            x = layers.GlobalAveragePooling2D()(x)\n","        elif pooling == 'max':\n","            x = layers.GlobalMaxPooling2D()(x)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`.\n","    if input_tensor is not None:\n","        inputs = keras_utils.get_source_inputs(input_tensor)\n","    else:\n","        inputs = img_input\n","    # Create model.\n","    model = models.Model(inputs, x, name='xception')\n","\n","    # Load weights.\n","    if weights == 'imagenet':\n","        if include_top:\n","            weights_path = keras_utils.get_file(\n","                'xception_weights_tf_dim_ordering_tf_kernels.h5',\n","                TF_WEIGHTS_PATH,\n","                cache_subdir='models',\n","                file_hash='0a58e3b7378bc2990ea3b43d5981f1f6')\n","        else:\n","            weights_path = keras_utils.get_file(\n","                'xception_weights_tf_dim_ordering_tf_kernels_notop.h5',\n","                TF_WEIGHTS_PATH_NO_TOP,\n","                cache_subdir='models',\n","                file_hash='b0042744bf5b25fce3cb969f33bebb97')\n","        model.load_weights(weights_path)\n","        if backend.backend() == 'theano':\n","            keras_utils.convert_all_kernels_in_model(model)\n","    elif weights is not None:\n","        model.load_weights(weights)\n","\n","    return model\n","\n","\n","def preprocess_input(x, **kwargs):\n","    \"\"\"Preprocesses a numpy array encoding a batch of images.\n","\n","    # Arguments\n","        x: a 4D numpy array consists of RGB values within [0, 255].\n","\n","    # Returns\n","        Preprocessed array.\n","    \"\"\"\n","    return imagenet_utils.preprocess_input(x, mode='tf', **kwargs)"],"metadata":{"id":"ttyrCft1--Oc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#ForensicTransfer model in the paper \"ForensicTransfer: Weakly-supervised Domain Adaptation for Forgery Detection\" cited by the paper \"Detecting CNN-Generated Facial Images in Real-World Scenarios\" (as 13)"],"metadata":{"id":"ET64-tDI_zkd"}},{"cell_type":"code","source":[],"metadata":{"id":"Q1M4rjlZ_zEI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#DenseNet and more at: https://github.com/amilworks/GanDetection/blob/master/notebooks/1.0_DenseNetGanDetection.ipynb\n","\n"],"metadata":{"id":"-PRCgdvXG0qo"}},{"cell_type":"code","source":["class Bottleneck(nn.Module):\n","    def __init__(self, nChannels, growthRate):\n","        super(Bottleneck, self).__init__()\n","        interChannels = 4*growthRate\n","        self.bn1 = nn.BatchNorm2d(nChannels)\n","        self.conv1 = nn.Conv2d(nChannels, interChannels, kernel_size=1,\n","                               bias=False)\n","        self.bn2 = nn.BatchNorm2d(interChannels)\n","        self.conv2 = nn.Conv2d(interChannels, growthRate, kernel_size=3,\n","                               padding=1, bias=False)\n","\n","    def forward(self, x):\n","        out = self.conv1(F.relu(self.bn1(x)))\n","        out = self.conv2(F.relu(self.bn2(out)))\n","        out = torch.cat((x, out), 1)\n","        return out\n","\n","class SingleLayer(nn.Module):\n","    def __init__(self, nChannels, growthRate):\n","        super(SingleLayer, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(nChannels)\n","        self.conv1 = nn.Conv2d(nChannels, growthRate, kernel_size=3,\n","                               padding=1, bias=False)\n","\n","    def forward(self, x):\n","        out = self.conv1(F.relu(self.bn1(x)))\n","        out = torch.cat((x, out), 1)\n","        return out\n","\n","class Transition(nn.Module):\n","    def __init__(self, nChannels, nOutChannels):\n","        super(Transition, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(nChannels)\n","        self.conv1 = nn.Conv2d(nChannels, nOutChannels, kernel_size=1,\n","                               bias=False)\n","\n","    def forward(self, x):\n","        out = self.conv1(F.relu(self.bn1(x)))\n","        out = F.avg_pool2d(out, 2)\n","        return out\n","\n","\n","class DenseNet(nn.Module):\n","    def __init__(self, growthRate, depth, reduction, nClasses, bottleneck):\n","        super(DenseNet, self).__init__()\n","\n","        nDenseBlocks = (depth-4) // 3\n","        if bottleneck:\n","            nDenseBlocks //= 2\n","\n","        nChannels = 2*growthRate\n","        self.conv1 = nn.Conv2d(3, nChannels, kernel_size=3, padding=1,\n","                               bias=False)\n","        self.dense1 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n","        nChannels += nDenseBlocks*growthRate\n","        nOutChannels = int(math.floor(nChannels*reduction))\n","        self.trans1 = Transition(nChannels, nOutChannels)\n","\n","        nChannels = nOutChannels\n","        self.dense2 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n","        nChannels += nDenseBlocks*growthRate\n","        nOutChannels = int(math.floor(nChannels*reduction))\n","        self.trans2 = Transition(nChannels, nOutChannels)\n","\n","        nChannels = nOutChannels\n","        self.dense3 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n","        nChannels += nDenseBlocks*growthRate\n","\n","        self.bn1 = nn.BatchNorm2d(nChannels)\n","        self.fc = nn.Linear(nChannels, nClasses)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","            elif isinstance(m, nn.Linear):\n","                m.bias.data.zero_()\n","\n","    def _make_dense(self, nChannels, growthRate, nDenseBlocks, bottleneck):\n","        layers = []\n","        for i in range(int(nDenseBlocks)):\n","            if bottleneck:\n","                layers.append(Bottleneck(nChannels, growthRate))\n","            else:\n","                layers.append(SingleLayer(nChannels, growthRate))\n","            nChannels += growthRate\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.trans1(self.dense1(out))\n","        out = self.trans2(self.dense2(out))\n","        out = self.dense3(out)\n","        out = torch.squeeze(F.avg_pool2d(F.relu(self.bn1(out)), 8))\n","        out = F.log_softmax(self.fc(out))\n","        return out"],"metadata":{"id":"GBUiohPeWREs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# DenseNet at: https://github.com/pytorch/vision/blob/6db1569c89094cf23f3bc41f79275c45e9fcb3f3/torchvision/models/densenet.py#L126"],"metadata":{"id":"Y3WTKELuX6eQ"}},{"cell_type":"code","source":["import re\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.utils.checkpoint as cp\n","from collections import OrderedDict\n","from .utils import load_state_dict_from_url\n","from torch import Tensor\n","from torch.jit.annotations import List\n","\n","\n","__all__ = ['DenseNet', 'densenet121', 'densenet169', 'densenet201', 'densenet161']\n","\n","model_urls = {\n","    'densenet121': 'https://download.pytorch.org/models/densenet121-a639ec97.pth',\n","    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n","    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n","    'densenet161': 'https://download.pytorch.org/models/densenet161-8d451a50.pth',\n","}\n","\n","\n","class _DenseLayer(nn.Module):\n","    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate, memory_efficient=False):\n","        super(_DenseLayer, self).__init__()\n","        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n","        self.add_module('relu1', nn.ReLU(inplace=True)),\n","        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n","                                           growth_rate, kernel_size=1, stride=1,\n","                                           bias=False)),\n","        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n","        self.add_module('relu2', nn.ReLU(inplace=True)),\n","        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n","                                           kernel_size=3, stride=1, padding=1,\n","                                           bias=False)),\n","        self.drop_rate = float(drop_rate)\n","        self.memory_efficient = memory_efficient\n","\n","    def bn_function(self, inputs):\n","        # type: (List[Tensor]) -> Tensor\n","        concated_features = torch.cat(inputs, 1)\n","        bottleneck_output = self.conv1(self.relu1(self.norm1(concated_features)))  # noqa: T484\n","        return bottleneck_output\n","\n","    # todo: rewrite when torchscript supports any\n","    def any_requires_grad(self, input):\n","        # type: (List[Tensor]) -> bool\n","        for tensor in input:\n","            if tensor.requires_grad:\n","                return True\n","        return False\n","\n","    @torch.jit.unused  # noqa: T484\n","    def call_checkpoint_bottleneck(self, input):\n","        # type: (List[Tensor]) -> Tensor\n","        def closure(*inputs):\n","            return self.bn_function(inputs)\n","\n","        return cp.checkpoint(closure, *input)\n","\n","    @torch.jit._overload_method  # noqa: F811\n","    def forward(self, input):\n","        # type: (List[Tensor]) -> (Tensor)\n","        pass\n","\n","    @torch.jit._overload_method  # noqa: F811\n","    def forward(self, input):\n","        # type: (Tensor) -> (Tensor)\n","        pass\n","\n","    # torchscript does not yet support *args, so we overload method\n","    # allowing it to take either a List[Tensor] or single Tensor\n","    def forward(self, input):  # noqa: F811\n","        if isinstance(input, Tensor):\n","            prev_features = [input]\n","        else:\n","            prev_features = input\n","\n","        if self.memory_efficient and self.any_requires_grad(prev_features):\n","            if torch.jit.is_scripting():\n","                raise Exception(\"Memory Efficient not supported in JIT\")\n","\n","            bottleneck_output = self.call_checkpoint_bottleneck(prev_features)\n","        else:\n","            bottleneck_output = self.bn_function(prev_features)\n","\n","        new_features = self.conv2(self.relu2(self.norm2(bottleneck_output)))\n","        if self.drop_rate > 0:\n","            new_features = F.dropout(new_features, p=self.drop_rate,\n","                                     training=self.training)\n","        return new_features\n","\n","\n","class _DenseBlock(nn.ModuleDict):\n","    _version = 2\n","\n","    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate, memory_efficient=False):\n","        super(_DenseBlock, self).__init__()\n","        for i in range(num_layers):\n","            layer = _DenseLayer(\n","                num_input_features + i * growth_rate,\n","                growth_rate=growth_rate,\n","                bn_size=bn_size,\n","                drop_rate=drop_rate,\n","                memory_efficient=memory_efficient,\n","            )\n","            self.add_module('denselayer%d' % (i + 1), layer)\n","\n","    def forward(self, init_features):\n","        features = [init_features]\n","        for name, layer in self.items():\n","            new_features = layer(features)\n","            features.append(new_features)\n","        return torch.cat(features, 1)\n","\n","\n","class _Transition(nn.Sequential):\n","    def __init__(self, num_input_features, num_output_features):\n","        super(_Transition, self).__init__()\n","        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n","        self.add_module('relu', nn.ReLU(inplace=True))\n","        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n","                                          kernel_size=1, stride=1, bias=False))\n","        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n","\n","\n","class DenseNet(nn.Module):\n","    r\"\"\"Densenet-BC model class, based on\n","    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n","\n","    Args:\n","        growth_rate (int) - how many filters to add each layer (`k` in paper)\n","        block_config (list of 4 ints) - how many layers in each pooling block\n","        num_init_features (int) - the number of filters to learn in the first convolution layer\n","        bn_size (int) - multiplicative factor for number of bottle neck layers\n","          (i.e. bn_size * k features in the bottleneck layer)\n","        drop_rate (float) - dropout rate after each dense layer\n","        num_classes (int) - number of classification classes\n","        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n","          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n","    \"\"\"\n","\n","    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n","                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000, memory_efficient=False):\n","\n","        super(DenseNet, self).__init__()\n","\n","        # First convolution\n","        self.features = nn.Sequential(OrderedDict([\n","            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2,\n","                                padding=3, bias=False)),\n","            ('norm0', nn.BatchNorm2d(num_init_features)),\n","            ('relu0', nn.ReLU(inplace=True)),\n","            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n","        ]))\n","\n","        # Each denseblock\n","        num_features = num_init_features\n","        for i, num_layers in enumerate(block_config):\n","            block = _DenseBlock(\n","                num_layers=num_layers,\n","                num_input_features=num_features,\n","                bn_size=bn_size,\n","                growth_rate=growth_rate,\n","                drop_rate=drop_rate,\n","                memory_efficient=memory_efficient\n","            )\n","            self.features.add_module('denseblock%d' % (i + 1), block)\n","            num_features = num_features + num_layers * growth_rate\n","            if i != len(block_config) - 1:\n","                trans = _Transition(num_input_features=num_features,\n","                                    num_output_features=num_features // 2)\n","                self.features.add_module('transition%d' % (i + 1), trans)\n","                num_features = num_features // 2\n","\n","        # Final batch norm\n","        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n","\n","        # Linear layer\n","        self.classifier = nn.Linear(num_features, num_classes)\n","\n","        # Official init from torch repo.\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.constant_(m.bias, 0)\n","\n","    def forward(self, x):\n","        features = self.features(x)\n","        out = F.relu(features, inplace=True)\n","        out = F.adaptive_avg_pool2d(out, (1, 1))\n","        out = torch.flatten(out, 1)\n","        out = self.classifier(out)\n","        return out\n","\n","\n","def _load_state_dict(model, model_url, progress):\n","    # '.'s are no longer allowed in module names, but previous _DenseLayer\n","    # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n","    # They are also in the checkpoints in model_urls. This pattern is used\n","    # to find such keys.\n","    pattern = re.compile(\n","        r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n","\n","    state_dict = load_state_dict_from_url(model_url, progress=progress)\n","    for key in list(state_dict.keys()):\n","        res = pattern.match(key)\n","        if res:\n","            new_key = res.group(1) + res.group(2)\n","            state_dict[new_key] = state_dict[key]\n","            del state_dict[key]\n","    model.load_state_dict(state_dict)\n","\n","\n","def _densenet(arch, growth_rate, block_config, num_init_features, pretrained, progress,\n","              **kwargs):\n","    model = DenseNet(growth_rate, block_config, num_init_features, **kwargs)\n","    if pretrained:\n","        _load_state_dict(model, model_urls[arch], progress)\n","    return model\n","\n","\n","def densenet121(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"Densenet-121 model from\n","    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n","          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n","    \"\"\"\n","    return _densenet('densenet121', 32, (6, 12, 24, 16), 64, pretrained, progress,\n","                     **kwargs)\n","\n","\n","def densenet161(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"Densenet-161 model from\n","    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n","          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n","    \"\"\"\n","    return _densenet('densenet161', 48, (6, 12, 36, 24), 96, pretrained, progress,\n","                     **kwargs)\n","\n","\n","def densenet169(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"Densenet-169 model from\n","    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n","          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n","    \"\"\"\n","    return _densenet('densenet169', 32, (6, 12, 32, 32), 64, pretrained, progress,\n","                     **kwargs)\n","\n","\n","def densenet201(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"Densenet-201 model from\n","    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n","          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n","    \"\"\"\n","    return _densenet('densenet201', 32, (6, 12, 48, 32), 64, pretrained, progress,\n","                     **kwargs)"],"metadata":{"id":"YWHW3Sv1X1lR"},"execution_count":null,"outputs":[]}]}